{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColonCancerDeepMIL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-UZwyweHtMG"
      },
      "source": [
        "import tarfile as tf\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from matplotlib.image import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZij962-H95e"
      },
      "source": [
        "def extData(path, dest):\n",
        "    if not os.path.isdir(dest):\n",
        "        print(\"Extracting Data...\")\n",
        "        f = tf.open(path)\n",
        "        f.extractall(dest)\n",
        "        f.close()\n",
        "    else:\n",
        "        print(\"Data already present.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY9CEtb1aOP7",
        "outputId": "bdde6720-5387-420f-fc2a-5f811cdea991"
      },
      "source": [
        "extData('/content/drive/MyDrive/Patches.tar.gz', '/content/drive/MyDrive/data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data already present.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcNvnlq7Hj8T"
      },
      "source": [
        "class CustomDataSet(Dataset):\n",
        "    def __init__(self, main_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        self.train_num = 89\n",
        "        self.test_num = 10\n",
        "        self.num0 = len(os.listdir(main_dir + '/0'))\n",
        "        self.num1 = len(os.listdir(main_dir + '/1'))\n",
        "        self.bags, self.labels = self._create_bags()\n",
        "\n",
        "    def _create_bags(self):\n",
        "      bag_list = []\n",
        "      label_list = []\n",
        "      for folder_label in os.listdir(main_dir):\n",
        "        path = os.path.join(main_dir, folder_label)\n",
        "        for img in os.listdir(path):\n",
        "          print(\"current image:\", img)\n",
        "          bag = []\n",
        "          path1 = os.path.join(path, img)\n",
        "          for patch in os.listdir(path1):\n",
        "            path2 = os.path.join(path1, patch)\n",
        "            nd_image = imread(path2)\n",
        "            image_tensor = self.transform(nd_image)\n",
        "            bag.append(image_tensor)\n",
        "          bag_list.append(bag)\n",
        "          label_list.append(torch.Tensor([int(folder_label)]))\n",
        "      temp = list(zip(bag_list, label_list))\n",
        "      shuffle(temp)\n",
        "      Sbag_list, Slabel_list = zip(*temp)\n",
        "      return Sbag_list, Slabel_list\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      b, l = self.bags[idx], self.labels[idx]\n",
        "      return b, l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ-yNlQtH6ac"
      },
      "source": [
        "tran =T.ToTensor()\n",
        "a = CustomDataSet('/content/drive/MyDrive/data/Patches', tran)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-2bQd-Ly8T-"
      },
      "source": [
        "a.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qydSgEWLW1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa6b23a-a00f-4ecf-adfb-1c25e1a3fd9b"
      },
      "source": [
        "\"\"\"Pytorch dataset object that loads MNIST dataset as bags.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "class MnistBags(data_utils.Dataset):\n",
        "    def __init__(self, target_number=9, mean_bag_length=10, var_bag_length=2, num_bag=250, seed=1, train=True):\n",
        "        self.target_number = target_number\n",
        "        self.mean_bag_length = mean_bag_length\n",
        "        self.var_bag_length = var_bag_length\n",
        "        self.num_bag = num_bag\n",
        "        self.train = train\n",
        "\n",
        "        self.r = np.random.RandomState(seed)\n",
        "\n",
        "        self.num_in_train = 60000\n",
        "        self.num_in_test = 10000\n",
        "\n",
        "        if self.train:\n",
        "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
        "        else:\n",
        "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
        "\n",
        "    def _create_bags(self):\n",
        "        if self.train:\n",
        "            loader = data_utils.DataLoader(datasets.MNIST('../datasets',\n",
        "                                                          train=True,\n",
        "                                                          download=True,\n",
        "                                                          transform=transforms.Compose([\n",
        "                                                              transforms.ToTensor(),\n",
        "                                                              transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                                           batch_size=self.num_in_train,\n",
        "                                           shuffle=False)\n",
        "        else:\n",
        "            loader = data_utils.DataLoader(datasets.MNIST('../datasets',\n",
        "                                                          train=False,\n",
        "                                                          download=True,\n",
        "                                                          transform=transforms.Compose([\n",
        "                                                              transforms.ToTensor(),\n",
        "                                                              transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                                           batch_size=self.num_in_test,\n",
        "                                           shuffle=False)\n",
        "\n",
        "        for (batch_data, batch_labels) in loader:\n",
        "            all_imgs = batch_data\n",
        "            all_labels = batch_labels\n",
        "\n",
        "        bags_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        for i in range(self.num_bag):\n",
        "            bag_length = np.int(self.r.normal(self.mean_bag_length, self.var_bag_length, 1))\n",
        "            if bag_length < 1:\n",
        "                bag_length = 1\n",
        "\n",
        "            if self.train:\n",
        "                indices = torch.LongTensor(self.r.randint(0, self.num_in_train, bag_length))\n",
        "            else:\n",
        "                indices = torch.LongTensor(self.r.randint(0, self.num_in_test, bag_length))\n",
        "\n",
        "            labels_in_bag = all_labels[indices]\n",
        "            labels_in_bag = labels_in_bag == self.target_number\n",
        "            #print(len(all_imgs[indices]))\n",
        "            bags_list.append(all_imgs[indices])\n",
        "            labels_list.append(labels_in_bag)\n",
        "\n",
        "        return bags_list, labels_list\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.train_labels_list)\n",
        "        else:\n",
        "            return len(self.test_labels_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            bag = self.train_bags_list[index]\n",
        "            label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
        "        else:\n",
        "            bag = self.test_bags_list[index]\n",
        "            label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
        "\n",
        "        return bag, label\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_loader = data_utils.DataLoader(MnistBags(target_number=9,\n",
        "                                                   mean_bag_length=10,\n",
        "                                                   var_bag_length=2,\n",
        "                                                   num_bag=100,\n",
        "                                                   seed=1,\n",
        "                                                   train=True),\n",
        "                                         batch_size=1,\n",
        "                                         shuffle=True)\n",
        "\n",
        "    test_loader = data_utils.DataLoader(MnistBags(target_number=9,\n",
        "                                                  mean_bag_length=10,\n",
        "                                                  var_bag_length=2,\n",
        "                                                  num_bag=100,\n",
        "                                                  seed=1,\n",
        "                                                  train=False),\n",
        "                                        batch_size=1,\n",
        "                                        shuffle=False)\n",
        "\n",
        "    len_bag_list_train = []\n",
        "    mnist_bags_train = 0\n",
        "    print(\"train loaded data\", train_loader)\n",
        "    for batch_idx, (bag, label) in enumerate(train_loader):\n",
        "        print('bag ', batch_idx, ': ', bag.shape, sep='')\n",
        "        len_bag_list_train.append(int(bag.squeeze(0).size()[0]))\n",
        "        mnist_bags_train += label[0].numpy()[0]\n",
        "    print('Number positive train bags: {}/{}\\n'\n",
        "          'Number of instances per bag, mean: {}, max: {}, min {}\\n'.format(\n",
        "        mnist_bags_train, len(train_loader),\n",
        "        np.mean(len_bag_list_train), np.max(len_bag_list_train), np.min(len_bag_list_train)))\n",
        "\n",
        "    len_bag_list_test = []\n",
        "    mnist_bags_test = 0\n",
        "    for batch_idx, (bag, label) in enumerate(test_loader):\n",
        "        len_bag_list_test.append(int(bag.squeeze(0).size()[0]))\n",
        "        mnist_bags_test += label[0].numpy()[0]\n",
        "    print('Number positive test bags: {}/{}\\n'\n",
        "          'Number of instances per bag, mean: {}, max: {}, min {}\\n'.format(\n",
        "        mnist_bags_test, len(test_loader),\n",
        "        np.mean(len_bag_list_test), np.max(len_bag_list_test), np.min(len_bag_list_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loaded data <torch.utils.data.dataloader.DataLoader object at 0x7fc05203ee90>\n",
            "bag 0: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 1: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 2: torch.Size([1, 7, 1, 28, 28])\n",
            "bag 3: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 4: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 5: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 6: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 7: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 8: torch.Size([1, 12, 1, 28, 28])\n",
            "bag 9: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 10: torch.Size([1, 4, 1, 28, 28])\n",
            "bag 11: torch.Size([1, 12, 1, 28, 28])\n",
            "bag 12: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 13: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 14: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 15: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 16: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 17: torch.Size([1, 6, 1, 28, 28])\n",
            "bag 18: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 19: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 20: torch.Size([1, 5, 1, 28, 28])\n",
            "bag 21: torch.Size([1, 12, 1, 28, 28])\n",
            "bag 22: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 23: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 24: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 25: torch.Size([1, 5, 1, 28, 28])\n",
            "bag 26: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 27: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 28: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 29: torch.Size([1, 14, 1, 28, 28])\n",
            "bag 30: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 31: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 32: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 33: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 34: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 35: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 36: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 37: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 38: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 39: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 40: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 41: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 42: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 43: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 44: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 45: torch.Size([1, 7, 1, 28, 28])\n",
            "bag 46: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 47: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 48: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 49: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 50: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 51: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 52: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 53: torch.Size([1, 6, 1, 28, 28])\n",
            "bag 54: torch.Size([1, 14, 1, 28, 28])\n",
            "bag 55: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 56: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 57: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 58: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 59: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 60: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 61: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 62: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 63: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 64: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 65: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 66: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 67: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 68: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 69: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 70: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 71: torch.Size([1, 9, 1, 28, 28])\n",
            "bag 72: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 73: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 74: torch.Size([1, 12, 1, 28, 28])\n",
            "bag 75: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 76: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 77: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 78: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 79: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 80: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 81: torch.Size([1, 6, 1, 28, 28])\n",
            "bag 82: torch.Size([1, 6, 1, 28, 28])\n",
            "bag 83: torch.Size([1, 7, 1, 28, 28])\n",
            "bag 84: torch.Size([1, 7, 1, 28, 28])\n",
            "bag 85: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 86: torch.Size([1, 7, 1, 28, 28])\n",
            "bag 87: torch.Size([1, 12, 1, 28, 28])\n",
            "bag 88: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 89: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 90: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 91: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 92: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 93: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 94: torch.Size([1, 10, 1, 28, 28])\n",
            "bag 95: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 96: torch.Size([1, 11, 1, 28, 28])\n",
            "bag 97: torch.Size([1, 8, 1, 28, 28])\n",
            "bag 98: torch.Size([1, 13, 1, 28, 28])\n",
            "bag 99: torch.Size([1, 8, 1, 28, 28])\n",
            "Number positive train bags: 61/100\n",
            "Number of instances per bag, mean: 9.47, max: 14, min 4\n",
            "\n",
            "Number positive test bags: 56/100\n",
            "Number of instances per bag, mean: 9.7, max: 15, min 5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RstLQ4YBMoE2",
        "outputId": "e787e2b9-a22b-43d9-94c9-b46bb52c71c5"
      },
      "source": [
        "data = MnistBags(target_number=9, mean_bag_length=10, var_bag_length=2, num_bag=100, seed=1, train=False)\n",
        "bg, lb = data.__getitem__(1)\n",
        "print(bg.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUToDNRlLTLo"
      },
      "source": [
        "main_dir = '/content/drive/MyDrive/data/Patches'\n",
        "bag_list = []\n",
        "label_list = []\n",
        "for folder_label in os.listdir(main_dir):\n",
        "        path = os.path.join(main_dir, folder_label)\n",
        "        for img in os.listdir(path):\n",
        "          bag = []\n",
        "          path1 = os.path.join(path, img)\n",
        "          for patch in os.listdir(path1):\n",
        "            path2 = os.path.join(path1, patch)\n",
        "            patch_img = Image.open(path2).convert(\"RGB\")\n",
        "            bag.append(patch_img)\n",
        "          bag_list.append(bag)\n",
        "          label_list.append(folder_label)\n",
        "\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f88JpXnu0CkF",
        "outputId": "6b2e82a7-2962-4dee-8de8-9d0a7cdfc4bc"
      },
      "source": [
        "test = torch.Tensor([int('0')])\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    }
  ]
}